{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pickle\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting all the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting the classification datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the openml Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names and IDs of the datasets\n",
    "datasets = ['Diabetes', 'madelon', 'gina', 'kc1', 'Amazon_employee_access', 'arcene', 'labor']\n",
    "ids = [37, 1485, 41158, 1067, 4135, 1458, 4]\n",
    "\n",
    "# Dictionaries to store data\n",
    "Independent_Data = {}\n",
    "Dependent_Data = {}\n",
    "Data = {}\n",
    "\n",
    "# Fetch datasets and split into X and y\n",
    "for name, id in zip(datasets, ids):\n",
    "    dataset = openml.datasets.get_dataset(id)\n",
    "    df, _, _, _ = dataset.get_data(dataset_format=\"dataframe\")\n",
    "    \n",
    "    # Special handling for the 'gina' dataset where dependent variable is the first column\n",
    "    if name in ['gina']:\n",
    "        y = df.iloc[:, 0]  # First column as the dependent variable\n",
    "        X = df.iloc[:, 1:]  # Remaining columns as independent variables\n",
    "    elif name in ['kc1']:\n",
    "        X = df.drop('defects', axis=1)  # This will create a DataFrame 'X' by dropping the column 'defects'\n",
    "        y = df['defects']  # This will create a Series 'y' containing the values of the column 'defects'\n",
    "\n",
    "    else:\n",
    "        y = df.iloc[:, -1]  # Last column as the dependent variable\n",
    "        X = df.iloc[:, :-1]  # All columns except the last as independent variables\n",
    "    \n",
    "    # Store dataframes in dictionaries with appropriate names\n",
    "    Independent_Data[name] = X\n",
    "    Dependent_Data[name] = y\n",
    "    Data[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the UCI ML Repository Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names and IDs of the datasets\n",
    "datasets = ['Statlog_German_Credit_Data', 'Ionosphere', 'Connectionist_Bench_Sonar_Mines_vs_Rocks', \n",
    "            'Statlog_Australian_Credit_Approval', 'Fertility', 'Spambase', 'Blood_Transfusion_Service_Center', \n",
    "            'EEG_Eye_State', 'Iris', 'Tic_Tac_Toe_Endgame', \n",
    "            'Balance_Scale', 'Hepatitis', 'Credit_Approval']\n",
    "ids = [144, 52, 151, 143, 244, 94, 176, 264, 53, 101, 12, 46, 27]\n",
    "\n",
    "# Fetch datasets and split into X and y\n",
    "for name, id in zip(datasets, ids):\n",
    "    # Fetch the dataset using the UCI ML Repository\n",
    "    dataset = fetch_ucirepo(id=id)\n",
    "    \n",
    "    # Get X and y directly from dataset structure\n",
    "    X = dataset.data.features\n",
    "    y = dataset.data.targets\n",
    "    \n",
    "    # Combine X and y for the full dataframe\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Store dataframes in dictionaries with appropriate names\n",
    "    Independent_Data[name] = X\n",
    "    Dependent_Data[name] = y\n",
    "    Data[name] = df\n",
    "\n",
    "# Now we have:\n",
    "# Independent_Data: dictionary containing all independent data dataframes, keyed by dataset names\n",
    "# Dependent_Data: dictionary containing all dependent data dataframes, keyed by dataset names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting the regression data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names and IDs of the datasets\n",
    "datasets = ['fri_c3_1000_50', 'fri_c2_1000_25', 'fri_c4_500_50', 'fri_c4_1000_50', 'fri_c1_1000_25', 'fri_c1_500_50', 'fri_c3_1000_25', 'auto93','pyrim','autoPrice',\n",
    "            'boston']\n",
    "ids = [618, 589, 616, 607, 620, 637, 586, 569, 217,207,531]\n",
    "\n",
    "# Fetch datasets and split into X and y\n",
    "for name, id in zip(datasets, ids):\n",
    "    dataset = openml.datasets.get_dataset(id)\n",
    "    df, _, _, _ = dataset.get_data(dataset_format=\"dataframe\")\n",
    "    \n",
    "    y = df.iloc[:, -1]  # Last column as the dependent variable\n",
    "    X = df.iloc[:, :-1]  # All columns except the last as independent variables\n",
    "    \n",
    "    # Store dataframes in dictionaries with appropriate names\n",
    "    Independent_Data[name] = X\n",
    "    Dependent_Data[name] = y\n",
    "    Data[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect UCI ML Repo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names and IDs of the datasets\n",
    "datasets = ['Concrete_Compressive_Strength', 'Auto_MPG', 'Forest Fires', 'Servo','Airfoil_Self_Noise','Wine_Quality']\n",
    "ids = [165, 9, 162, 87,291,186]\n",
    "\n",
    "# Fetch datasets and split into X and y\n",
    "for name, id in zip(datasets, ids):\n",
    "    # Fetch the dataset using the UCI ML Repository\n",
    "    dataset = fetch_ucirepo(id=id)\n",
    "    \n",
    "    # Get X and y directly from dataset structure\n",
    "    X = dataset.data.features\n",
    "    y = dataset.data.targets\n",
    "    \n",
    "    # Combine X and y for the full dataframe\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    \n",
    "    # Store dataframes in dictionaries with appropriate names\n",
    "    Independent_Data[name] = X\n",
    "    Dependent_Data[name] = y\n",
    "    Data[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the directory containing the CSV files\n",
    "directory_path = 'Data/Kaggle Data'\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Get the file name without the extension to use as the dictionary key\n",
    "        key_name = os.path.splitext(file)[0]\n",
    "        \n",
    "        # Store all columns except the last in the Independent_Data dictionary\n",
    "        Independent_Data[key_name] = df.iloc[:, :-1]\n",
    "        \n",
    "        # Store the last column in the Dependent_Data dictionary\n",
    "        Dependent_Data[key_name] = df.iloc[:, -1]\n",
    "\n",
    "        Data[name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying dataframes with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe 'labor' has missing values.\n",
      "The dataframe 'Hepatitis' has missing values.\n",
      "The dataframe 'Credit_Approval' has missing values.\n",
      "The dataframe 'auto93' has missing values.\n",
      "The dataframe 'Auto_MPG' has missing values.\n"
     ]
    }
   ],
   "source": [
    "for name, df in Data.items():\n",
    "    # Check if any element is missing in the dataframe\n",
    "    if df.isnull().any().any():\n",
    "        print(f\"The dataframe '{name}' has missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing the missing values in the Hepatitis DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\2851439107.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  hepatitis_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\2851439107.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  hepatitis_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\2851439107.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  hepatitis_df[column].fillna(mean_value, inplace=True)  # Fill missing values with the mean\n"
     ]
    }
   ],
   "source": [
    "hepatitis_df = Independent_Data['Hepatitis']\n",
    "\n",
    "# Columns categorized by type\n",
    "categorical_columns = ['Steroid', 'Fatigue', 'Malaise', 'Anorexia', 'Liver Big', 'Liver Firm',\n",
    "                       'Spleen Palpable', 'Spiders', 'Ascites', 'Varices', 'Histology', 'Sex']\n",
    "integer_columns = ['Alk Phosphate', 'Sgot', 'Albumin', 'Protime']\n",
    "continuous_columns = ['Bilirubin']\n",
    "\n",
    "# Impute missing values for categorical columns with the mode\n",
    "for column in categorical_columns:\n",
    "    if hepatitis_df[column].isnull().any():\n",
    "        mode_value = hepatitis_df[column].mode()[0]  # Get the mode value for the column\n",
    "        hepatitis_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
    "\n",
    "# Impute missing values for integer columns with the mode\n",
    "for column in integer_columns:\n",
    "    if hepatitis_df[column].isnull().any():\n",
    "        mode_value = hepatitis_df[column].mode()[0]  # Get the mode value for the column\n",
    "        hepatitis_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
    "\n",
    "# Impute missing values for continuous columns with the mean\n",
    "for column in continuous_columns:\n",
    "    if hepatitis_df[column].isnull().any():\n",
    "        mean_value = hepatitis_df[column].mean()  # Get the mean value for the column\n",
    "        hepatitis_df[column].fillna(mean_value, inplace=True)  # Fill missing values with the mean\n",
    "\n",
    "# Update the dictionary with the modified dataframe\n",
    "Independent_Data['Hepatitis'] = hepatitis_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing the missing values in Credit Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\2934545606.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  credit_approval_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\2934545606.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  credit_approval_df[column].fillna(mean_value, inplace=True)  # Fill missing values with the mean\n"
     ]
    }
   ],
   "source": [
    "credit_approval_df = Independent_Data['Credit_Approval']\n",
    "\n",
    "# List of categorical and continuous columns\n",
    "categorical_columns = ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']\n",
    "continuous_columns = ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']\n",
    "\n",
    "# Impute missing values for categorical columns with the mode\n",
    "for column in categorical_columns:\n",
    "    if credit_approval_df[column].isnull().any():\n",
    "        mode_value = credit_approval_df[column].mode()[0]  # Get the mode value for the column\n",
    "        credit_approval_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
    "\n",
    "# Impute missing values for continuous columns with the mean\n",
    "for column in continuous_columns:\n",
    "    if credit_approval_df[column].isnull().any():\n",
    "        mean_value = credit_approval_df[column].mean()  # Get the mean value for the column\n",
    "        credit_approval_df[column].fillna(mean_value, inplace=True)  # Fill missing values with the mean\n",
    "\n",
    "# Update the dictionary with the modified dataframe\n",
    "Independent_Data['Credit_Approval'] = credit_approval_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing the missing values in the labor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\2522969137.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  labor_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\2522969137.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  labor_df[column].fillna(mean_value, inplace=True)  # Fill missing values with the mean\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the dictionary containing the 'labor' key with its DataFrame\n",
    "labor_df = Independent_Data['labor']\n",
    "\n",
    "# List of categorical and continuous columns\n",
    "categorical_columns = ['duration', 'cost-of-living-adjustment', 'working-hours', 'pension', \n",
    "                       'standby-pay', 'shift-differential', 'education-allowance', \n",
    "                       'statutory-holidays', 'vacation', 'longterm-disability-assistance', \n",
    "                       'contribution-to-dental-plan', 'bereavement-assistance', \n",
    "                       'contribution-to-health-plan']\n",
    "continuous_columns = ['wage-increase-first-year', 'wage-increase-second-year', 'wage-increase-third-year']\n",
    "\n",
    "# Impute missing values for categorical columns with the mode\n",
    "for column in categorical_columns:\n",
    "    if labor_df[column].isnull().any():  # Check if there are any missing values\n",
    "        mode_value = labor_df[column].mode()[0]  # Get the mode value for the column\n",
    "        labor_df[column].fillna(mode_value, inplace=True)  # Fill missing values with the mode\n",
    "\n",
    "# Impute missing values for continuous columns with the mean\n",
    "for column in continuous_columns:\n",
    "    if labor_df[column].isnull().any():  # Check if there are any missing values\n",
    "        mean_value = labor_df[column].mean()  # Get the mean value for the column\n",
    "        labor_df[column].fillna(mean_value, inplace=True)  # Fill missing values with the mean\n",
    "\n",
    "# Update the dictionary with the modified DataFrame\n",
    "Independent_Data['labor'] = labor_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing the missing values of auto93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\1077359190.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(df[column].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = Independent_Data['auto93']\n",
    "\n",
    "# List of numeric and nominal (categorical) features based on provided information\n",
    "numeric_features = [\n",
    "    'City_MPG', 'Highway_MPG', 'Number_of_cylinders',\n",
    "    'Engine_size', 'Horsepower', 'RPM', 'Engine_revolutions_per_mile',\n",
    "    'Fuel_tank_capacity', 'Passenger_capacity', 'Length', 'Wheelbase',\n",
    "    'Width', 'U-turn_space', 'Rear_seat_room', 'Luggage_capacity', 'Weight'\n",
    "]\n",
    "\n",
    "nominal_features = [\n",
    "    'Manufacturer', 'Type', 'Air_Bags_standard', 'Drive_train_type',\n",
    "    'Manual_transmission_available', 'Domestic'\n",
    "]\n",
    "\n",
    "# Converting numeric features to float64\n",
    "df[numeric_features] = df[numeric_features].astype('float64')\n",
    "\n",
    "# Converting nominal features to category\n",
    "df[nominal_features] = df[nominal_features].astype('category')\n",
    "\n",
    "# Imputing missing values in numeric features with the mean\n",
    "for column in numeric_features:\n",
    "    if df[column].isnull().any():\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "# Imputing missing values in categorical features with the mode\n",
    "for column in nominal_features:\n",
    "    if df[column].isnull().any():\n",
    "        mode_value = df[column].mode()[0]  # Getting the mode value of the column\n",
    "        df[column].fillna(mode_value, inplace=True)\n",
    "\n",
    "Independent_Data['auto93'] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputing the missing values of Auto_MPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\25644574\\AppData\\Local\\Temp\\ipykernel_20968\\1293635888.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['horsepower'].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Assuming Independent_Data is your dictionary containing the DataFrame\n",
    "df = Independent_Data['Auto_MPG']\n",
    "\n",
    "# Check if there are missing values in the 'horsepower' column\n",
    "if df['horsepower'].isnull().any():\n",
    "    # Calculate the mean of the 'horsepower' column, excluding NaN values\n",
    "    mean_value = df['horsepower'].mean()\n",
    "    \n",
    "    # Impute missing values in the 'horsepower' column with the mean\n",
    "    df['horsepower'].fillna(mean_value, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to the dictionary\n",
    "Independent_Data['Auto_MPG'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting series to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Series to DataFrame\n",
    "for key, value in Dependent_Data.items():\n",
    "    if isinstance(value, pd.Series):\n",
    "        Dependent_Data[key] = value.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Categorical Column Types to category and Int/Cts to float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statlog German Credit Data\n",
    "Dependent_Data['Statlog_German_Credit_Data']['class'] = Dependent_Data['Statlog_German_Credit_Data']['class'].astype('category')\n",
    "\n",
    "#Statlog_Australian_Credit_Approval\n",
    "\n",
    "# List of categorical and continuous variables for 'Statlog_Australian_Credit_Approval'\n",
    "categorical_columns = ['A1', 'A4', 'A5', 'A6', 'A8', 'A9', 'A11', 'A12']\n",
    "continuous_columns = ['A2', 'A3', 'A7', 'A10', 'A13', 'A14']\n",
    "\n",
    "# Convert categorical variables to 'category' type\n",
    "for column in categorical_columns:\n",
    "    if column in Independent_Data['Statlog_Australian_Credit_Approval'].columns:\n",
    "        Independent_Data['Statlog_Australian_Credit_Approval'][column] = Independent_Data['Statlog_Australian_Credit_Approval'][column].astype('category')\n",
    "\n",
    "# Convert continuous variables to 'float64' type\n",
    "for column in continuous_columns:\n",
    "    if column in Independent_Data['Statlog_Australian_Credit_Approval'].columns:\n",
    "        Independent_Data['Statlog_Australian_Credit_Approval'][column] = Independent_Data['Statlog_Australian_Credit_Approval'][column].astype('float64')\n",
    "\n",
    "Dependent_Data['Statlog_Australian_Credit_Approval']['A15'] = Dependent_Data['Statlog_Australian_Credit_Approval']['A15'].astype('category')\n",
    "\n",
    "#Fertility Data\n",
    "\n",
    "# Define the categorical and numeric variables for 'Fertility'\n",
    "categorical_columns = ['high_fevers', 'alcohol', 'smoking', 'child_diseases', 'accident', 'surgical_intervention']\n",
    "numeric_columns = ['season', 'age', 'hrs_sitting']  # These include both continuous and integer variables\n",
    "\n",
    "# Convert categorical variables to 'category' type\n",
    "for column in categorical_columns:\n",
    "    if column in Independent_Data['Fertility'].columns:\n",
    "        Independent_Data['Fertility'][column] = Independent_Data['Fertility'][column].astype('category')\n",
    "\n",
    "# Convert numeric variables to 'float64' type\n",
    "for column in numeric_columns:\n",
    "    if column in Independent_Data['Fertility'].columns:\n",
    "        Independent_Data['Fertility'][column] = Independent_Data['Fertility'][column].astype('float64')\n",
    "\n",
    "#Spambase\n",
    "Dependent_Data['Spambase']['Class'] = Dependent_Data['Spambase']['Class'].astype('category')\n",
    "\n",
    "#Blood_Transfusion_Service_Center\n",
    "Dependent_Data['Blood_Transfusion_Service_Center']['Donated_Blood'] = Dependent_Data['Blood_Transfusion_Service_Center']['Donated_Blood'].astype('category')\n",
    "\n",
    "#Gina\n",
    "# Convert all columns in the DataFrame to 'float64' data type\n",
    "for column in Independent_Data['gina'].columns:\n",
    "    Independent_Data['gina'][column] = Independent_Data['gina'][column].astype('float64')\n",
    "\n",
    "#Arcene\n",
    "# Convert all columns in the DataFrame to 'float64' data type\n",
    "for column in Independent_Data['arcene'].columns:\n",
    "    Independent_Data['arcene'][column] = Independent_Data['arcene'][column].astype('float64')\n",
    "\n",
    "#EEG_Eye_State\n",
    "Dependent_Data['EEG_Eye_State']['eyeDetection'] = Dependent_Data['EEG_Eye_State']['eyeDetection'].astype('category')\n",
    "\n",
    "#kc1\n",
    "# Convert all columns in the DataFrame to 'float64' data type\n",
    "for column in Independent_Data['kc1'].columns:\n",
    "    Independent_Data['kc1'][column] = Independent_Data['kc1'][column].astype('float64')\n",
    "\n",
    "\n",
    "Dependent_Data['kc1']['defects'] = Dependent_Data['kc1']['defects'].astype('category')\n",
    "\n",
    "#Airfoil_Self_Noise\n",
    "\n",
    "# Convert 'attack-angle' to category\n",
    "Independent_Data['Airfoil_Self_Noise']['attack-angle'] = Independent_Data['Airfoil_Self_Noise']['attack-angle'].astype('category')\n",
    "\n",
    "# Convert all other columns to float64\n",
    "for column in Independent_Data['Airfoil_Self_Noise'].columns:\n",
    "    if column != 'attack-angle':  # Skip the 'attack-angle' column\n",
    "        Independent_Data['Airfoil_Self_Noise'][column] = Independent_Data['Airfoil_Self_Noise'][column].astype('float64')\n",
    "\n",
    "\n",
    "Dependent_Data['Airfoil_Self_Noise']['scaled-sound-pressure'] = Dependent_Data['Airfoil_Self_Noise']['scaled-sound-pressure'].astype('float64')\n",
    "\n",
    "#Balance_Scale\n",
    "# Convert all columns in the DataFrame to 'category' data type\n",
    "for column in Independent_Data['Balance_Scale'].columns:\n",
    "    Independent_Data['Balance_Scale'][column] = Independent_Data['Balance_Scale'][column].astype('category')\n",
    "\n",
    "# Define categorical and continuous variables for 'Hepatitis'\n",
    "categorical_variables = [\n",
    "    'Sex', 'Steroid', 'Antivirals', 'Fatigue', 'Malaise', \n",
    "    'Anorexia', 'Liver Big', 'Liver Firm', 'Spleen Palpable', \n",
    "    'Spiders', 'Ascites', 'Varices'\n",
    "]\n",
    "continuous_variables = [\n",
    "    'Bilirubin', 'Age', 'Alk Phosphate', 'Sgot', 'Albumin', 'Protime', 'Histology'\n",
    "]\n",
    "\n",
    "# Convert categorical variables to 'category'\n",
    "for column in categorical_variables:\n",
    "    if column in Independent_Data['Hepatitis'].columns:\n",
    "        Independent_Data['Hepatitis'][column] = Independent_Data['Hepatitis'][column].astype('category')\n",
    "\n",
    "# Convert continuous variables to 'float64'\n",
    "for column in continuous_variables:\n",
    "    if column in Independent_Data['Hepatitis'].columns:\n",
    "        Independent_Data['Hepatitis'][column] = Independent_Data['Hepatitis'][column].astype('float64')\n",
    "\n",
    "Dependent_Data['Hepatitis']['Class'] = Dependent_Data['Hepatitis']['Class'].astype('category')\n",
    "\n",
    "#pyrim\n",
    "Independent_Data['pyrim']['p3_pi_acceptor'] = Independent_Data['pyrim']['p3_pi_acceptor'].astype('float64')\n",
    "\n",
    "#Auto_MPG\n",
    "Independent_Data['Auto_MPG']['weight'] = Independent_Data['Auto_MPG']['weight'].astype('float64')\n",
    "\n",
    "#autoPrice\n",
    "Independent_Data['autoPrice']['horsepower'] = Independent_Data['autoPrice']['horsepower'].astype('float64')\n",
    "Independent_Data['autoPrice']['city-mpg'] = Independent_Data['autoPrice']['city-mpg'].astype('float64')\n",
    "Independent_Data['autoPrice']['highway-mpg'] = Independent_Data['autoPrice']['highway-mpg'].astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for values with infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframes with infinity or negative infinity values: []\n"
     ]
    }
   ],
   "source": [
    "# Assuming the dictionary 'Independent_Data' is defined and contains dataframes\n",
    "dataframes_with_infinities = {}\n",
    "\n",
    "# Check each dataframe for infinity or negative infinity values in numeric columns\n",
    "for name, df in Independent_Data.items():\n",
    "    # Select columns that are not of type 'object' or 'category'\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if np.isinf(numeric_df.values).any():  # Check if any element is +/- infinity\n",
    "        dataframes_with_infinities[name] = df\n",
    "\n",
    "# Output the names of dataframes containing infinity values\n",
    "print(\"Dataframes with infinity or negative infinity values:\", list(dataframes_with_infinities.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking unique data types of regression datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fri_c3_1000_50: [dtype('float64')]\n",
      "fri_c2_1000_25: [dtype('float64')]\n",
      "fri_c4_500_50: [dtype('float64')]\n",
      "fri_c4_1000_50: [dtype('float64')]\n",
      "fri_c1_1000_25: [dtype('float64')]\n",
      "fri_c1_500_50: [dtype('float64')]\n",
      "fri_c3_1000_25: [dtype('float64')]\n",
      "auto93: [CategoricalDtype(categories=['Acura', 'Audi', 'BMW', 'Buick', 'Cadillac', 'Chevrolet',\n",
      "                   'Chrysler', 'Dodge', 'Eagle', 'Ford', 'Geo', 'Honda',\n",
      "                   'Hyundai', 'Infiniti', 'Lexus', 'Lincoln', 'Mazda',\n",
      "                   'Mercedes-Benz', 'Mercury', 'Mitsubishi', 'Nissan',\n",
      "                   'Oldsmobile', 'Plymouth', 'Pontiac', 'Saab', 'Saturn',\n",
      "                   'Subaru', 'Suzuki', 'Toyota', 'Volkswagen', 'Volvo'],\n",
      " , ordered=True, categories_dtype=object)\n",
      " CategoricalDtype(categories=['Small', 'Midsize', 'Compact', 'Large', 'Sporty', 'Van'], ordered=True, categories_dtype=object)\n",
      " dtype('float64')\n",
      " CategoricalDtype(categories=['0', '2', '1'], ordered=True, categories_dtype=object)\n",
      " CategoricalDtype(categories=['1', '0', '2'], ordered=True, categories_dtype=object)\n",
      " CategoricalDtype(categories=['1', '0'], ordered=True, categories_dtype=object)\n",
      " CategoricalDtype(categories=['0', '1'], ordered=True, categories_dtype=object)]\n",
      "pyrim: [dtype('float64')]\n",
      "autoPrice: [dtype('float64')]\n",
      "boston: [dtype('float64')\n",
      " CategoricalDtype(categories=['0', '1'], ordered=True, categories_dtype=object)\n",
      " CategoricalDtype(categories=['1', '2', '3', '4', '5', '6', '7', '8', '24'], ordered=True, categories_dtype=object)]\n",
      "Concrete_Compressive_Strength: [dtype('float64') dtype('int64')]\n",
      "Auto_MPG: [dtype('float64') dtype('int64')]\n",
      "Forest Fires: [dtype('int64') dtype('O') dtype('float64')]\n",
      "Servo: [dtype('O') dtype('int64')]\n",
      "Airfoil_Self_Noise: [dtype('float64')\n",
      " CategoricalDtype(categories=[ 0.0,  1.5,  2.0,  2.7,  3.0,  3.3,  4.0,  4.2,  4.8,  5.3,\n",
      "                    5.4,  6.7,  7.2,  7.3,  8.4,  8.9,  9.5,  9.9, 11.2, 12.3,\n",
      "                   12.6, 12.7, 15.4, 15.6, 17.4, 19.7, 22.2],\n",
      " , ordered=False, categories_dtype=float64)                                              ]\n",
      "Wine_Quality: [dtype('float64')]\n",
      "BodyFat: [dtype('float64') dtype('int64')]\n",
      "California_Housing: [dtype('float64')]\n",
      "Quake: [dtype('int64') dtype('float64')]\n"
     ]
    }
   ],
   "source": [
    "regression_datasets = [\n",
    "    'fri_c3_1000_50', 'fri_c2_1000_25', 'fri_c4_500_50', 'fri_c4_1000_50', \n",
    "    'fri_c1_1000_25', 'fri_c1_500_50', 'fri_c3_1000_25', 'auto93', 'pyrim', \n",
    "    'autoPrice', 'boston', 'Concrete_Compressive_Strength', 'Auto_MPG', \n",
    "    'Forest Fires', 'Servo', 'Airfoil_Self_Noise', 'Wine_Quality', \n",
    "    'BodyFat', 'California_Housing', 'Quake'\n",
    "]\n",
    "\n",
    "for name in regression_datasets:\n",
    "    if name in Independent_Data:\n",
    "        df = Independent_Data[name]\n",
    "        unique_dtypes = df.dtypes.unique()\n",
    "        print(f\"{name}: {unique_dtypes}\")\n",
    "    else:\n",
    "        print(f\"{name}: Not found in Independent_Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the data for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize the dictionaries themselves\n",
    "pickle.dump(Independent_Data, open('Data/Independent_Data_dictionary.pkl', 'wb'))\n",
    "pickle.dump(Dependent_Data, open('Data/Dependent_Data_dictionary.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
