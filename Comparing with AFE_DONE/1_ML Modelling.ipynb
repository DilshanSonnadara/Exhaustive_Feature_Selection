{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    AdaBoostRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading models and Data and converting the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "# METHOD_FOLDERS = [\"AUTOFEAT\", \"FT\", \"OPENFE\", \"SAFE\"]  # expected subfolders\n",
    "METHOD_FOLDERS = [\"BASIC\",\"AUTOFEAT\", \"FT\", \"OPENFE\", \"SAFE\"]  # expected subfolders\n",
    "PREDICTIONS_DIR = \"Predictions\"  # where we write pickles with predictions\n",
    "os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -----------------------------\n",
    "# Define models (with sensible scaling where needed)\n",
    "# -----------------------------\n",
    "def build_models():\n",
    "    # Define regression models\n",
    "    regression_models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"KNN Regression\": KNeighborsRegressor(),\n",
    "        \"SVM Regression\": SVR(),\n",
    "        \"Random Forest Regression\": RandomForestRegressor(random_state=42),\n",
    "        \"AdaBoost Regression\": AdaBoostRegressor(random_state=42),\n",
    "        \"MLP Regression\": MLPRegressor(random_state=42),\n",
    "        \"Decision Tree Regression\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Extremely Randomized Trees Regression\": ExtraTreesRegressor(random_state=42),\n",
    "        \"Gradient Boosting Regression\": GradientBoostingRegressor(random_state=42),\n",
    "        \"LightGBM Regression\": lgb.LGBMRegressor(random_state=42,verbose = -1),\n",
    "        \"XGBoost Regression\": xgb.XGBRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    return regression_models\n",
    "\n",
    "# def ensure_1d_target(y):\n",
    "#     # Make y a 1-D vector\n",
    "#     if isinstance(y, pd.DataFrame):\n",
    "#         if y.shape[1] != 1:\n",
    "#             raise ValueError(f\"y must be 1-D; got shape {y.shape}\")\n",
    "#         y = y.iloc[:, 0]\n",
    "#         print('IT HIT HERE')\n",
    "#     return np.ravel(y)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def load_method_datasets(method_folder):\n",
    "    \"\"\"\n",
    "    Read all *.pkl files under method_folder.\n",
    "    Each file is assumed to be: { 'fold1': {...}, ..., 'fold5': {...} }.\n",
    "    Returns dict: dataset_name -> folds_dict\n",
    "    \"\"\"\n",
    "    path_pattern = os.path.join(method_folder, \"*.pkl\")\n",
    "    files = sorted(glob(path_pattern))\n",
    "    data = {}\n",
    "    for fp in files:\n",
    "        dataset_name = os.path.splitext(os.path.basename(fp))[0]\n",
    "        with open(fp, \"rb\") as f:\n",
    "            try:\n",
    "                obj = pickle.load(f)\n",
    "            except EOFError:\n",
    "                warnings.warn(f\"EOFError reading {fp}; skipping.\")\n",
    "                continue\n",
    "        # basic sanity check\n",
    "        if not isinstance(obj, dict):\n",
    "            warnings.warn(f\"Unexpected content in {fp} (not a dict); skipping.\")\n",
    "            continue\n",
    "        expected_folds = {\"fold1\", \"fold2\", \"fold3\", \"fold4\", \"fold5\"}\n",
    "        if not expected_folds.issubset(set(obj.keys())):\n",
    "            warnings.warn(f\"{fp} does not contain the expected folds; skipping.\")\n",
    "            continue\n",
    "        data[dataset_name] = obj\n",
    "    return data\n",
    "\n",
    "def to_1d(y):\n",
    "    \"\"\"Ensure y is a 1D array-like.\"\"\"\n",
    "    if y is None:\n",
    "        return None\n",
    "    y = np.asarray(y)\n",
    "    return y.ravel()\n",
    "\n",
    "def rename_duplicates(old_columns):\n",
    "    # Dictionary to count occurrences of each column name\n",
    "    counts = {}\n",
    "    new_columns = []\n",
    "    for column in old_columns:\n",
    "        if column in counts:\n",
    "            counts[column] += 1\n",
    "            new_columns.append(f\"{column}_{counts[column]}\")\n",
    "        else:\n",
    "            counts[column] = 0\n",
    "            new_columns.append(column)\n",
    "    return new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Fitting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Phase 1: Train and Save Predictions\n",
    "# -----------------------------\n",
    "def generate_and_save_predictions():\n",
    "    \"\"\"\n",
    "    For each method folder, train all models per dataset/fold and\n",
    "    save predictions + y_true into one pickle per method.\n",
    "    Pickle schema:\n",
    "    { dataset_name:\n",
    "        { fold_name:\n",
    "            { model_name: {\"y_true\": np.ndarray, \"y_pred\": np.ndarray} }\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    models = build_models()\n",
    "    for method in METHOD_FOLDERS:\n",
    "        print(f\"\\n=== Processing method: {method} ===\")\n",
    "        method_data = load_method_datasets(method)\n",
    "        method_pred_store = {}\n",
    "\n",
    "        for dataset_name, folds_dict in method_data.items():\n",
    "            print(f\"  - Dataset: {dataset_name}\")\n",
    "            method_pred_store[dataset_name] = {}\n",
    "\n",
    "            for fold_name, fold_payload in folds_dict.items():\n",
    "                # Expected keys: Training_Independent, Training_Dependent, Testing_Independent, Testing_Dependent, Timing\n",
    "                X_tr = fold_payload.get(\"Training_Independent\")\n",
    "                y_tr = to_1d(fold_payload.get(\"Training_Dependent\"))\n",
    "                X_te = fold_payload.get(\"Testing_Independent\")\n",
    "                y_te = to_1d(fold_payload.get(\"Testing_Dependent\"))\n",
    "\n",
    "                X_tr.columns = [col.replace('{', '').replace('}', '').replace(':', '').replace('\"', '').replace(\"'\", '').replace('[', '').replace(']', '').replace(')', '').replace(',', '_').replace('.', '_').replace(' ', '').replace('(','_')  for col in X_tr.columns]\n",
    "                X_te.columns = [col.replace('{', '').replace('}', '').replace(':', '').replace('\"', '').replace(\"'\", '').replace('[', '').replace(']', '').replace(')', '').replace(',', '_').replace('.', '_').replace(' ', '').replace('(','_') for col in X_te.columns]\n",
    "                # Renaming duplicated columns\n",
    "                X_tr.columns = rename_duplicates(X_tr.columns)\n",
    "                X_te.columns = rename_duplicates(X_te.columns)\n",
    "\n",
    "                if X_tr is None or y_tr is None or X_te is None or y_te is None:\n",
    "                    warnings.warn(f\"Missing data in {method}/{dataset_name}/{fold_name}; skipping this fold.\")\n",
    "                    continue\n",
    "\n",
    "                method_pred_store[dataset_name][fold_name] = {}\n",
    "\n",
    "                for model_name, model in models.items():\n",
    "                    # Recreate model fresh for each fit (avoid state carry-over)\n",
    "                    # For pipelines, clone by rebuilding from build_models()\n",
    "                    model_fresh = build_models()[model_name]\n",
    "                    try:\n",
    "                        model_fresh.fit(X_tr, y_tr)\n",
    "                        y_pred = model_fresh.predict(X_te)\n",
    "                    except Exception as e:\n",
    "                        warnings.warn(f\"Model {model_name} failed on {method}/{dataset_name}/{fold_name}: {e}\")\n",
    "                        y_pred = np.full_like(y_te, fill_value=np.nan, dtype=float)\n",
    "\n",
    "                    method_pred_store[dataset_name][fold_name][model_name] = {\n",
    "                        \"y_true\": np.asarray(y_te),\n",
    "                        \"y_pred\": np.asarray(y_pred, dtype=float),\n",
    "                    }\n",
    "\n",
    "        # Write out per-method predictions\n",
    "        out_fp = os.path.join(PREDICTIONS_DIR, f\"{method}_predictions.pkl\")\n",
    "        with open(out_fp, \"wb\") as f:\n",
    "            pickle.dump(method_pred_store, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Saved predictions for {method} -> {out_fp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Phase 2: Reload and Compute RMSE (averaged across 5 folds)\n",
    "# -----------------------------\n",
    "def compute_rmse_from_saved_predictions():\n",
    "    \"\"\"\n",
    "    Reads each method's prediction pickle and computes:\n",
    "    Test RMSE averaged across folds per (Dataset, Model, Method).\n",
    "\n",
    "    Returns a wide DataFrame:\n",
    "    columns = ['Dataset', 'Model', 'AutoFeat', 'SAFE', 'FT', 'OpenFE']\n",
    "    \"\"\"\n",
    "    # Load all method prediction pickles\n",
    "    method_to_preds = {}\n",
    "    for method in METHOD_FOLDERS:\n",
    "        pred_fp = os.path.join(PREDICTIONS_DIR, f\"{method}_predictions.pkl\")\n",
    "        if not os.path.exists(pred_fp):\n",
    "            warnings.warn(f\"Predictions file not found for {method}: {pred_fp}.\")\n",
    "            continue\n",
    "        with open(pred_fp, \"rb\") as f:\n",
    "            method_to_preds[method] = pickle.load(f)\n",
    "\n",
    "    # Aggregate RMSE per dataset, per model, per method across folds\n",
    "    rows = []\n",
    "    for method, all_datasets in method_to_preds.items():\n",
    "        for dataset_name, folds_dict in all_datasets.items():\n",
    "            # model_name -> list of fold RMSEs\n",
    "            model_to_fold_rmses = {}\n",
    "\n",
    "            for fold_name, models_dict in folds_dict.items():\n",
    "                for model_name, payload in models_dict.items():\n",
    "                    y_true = payload.get(\"y_true\", None)\n",
    "                    y_pred = payload.get(\"y_pred\", None)\n",
    "                    if y_true is None or y_pred is None or len(y_true) == 0:\n",
    "                        continue\n",
    "                    # Skip NaN predictions\n",
    "                    if np.isnan(y_pred).any():\n",
    "                        continue\n",
    "                    rmse = mean_squared_error(y_true, y_pred)**0.5\n",
    "                    model_to_fold_rmses.setdefault(model_name, []).append(rmse)\n",
    "\n",
    "            # Average across folds\n",
    "            for model_name, rmse_list in model_to_fold_rmses.items():\n",
    "                if len(rmse_list) == 0:\n",
    "                    continue\n",
    "                avg_rmse = float(np.mean(rmse_list))\n",
    "                rows.append({\n",
    "                    \"Dataset\": dataset_name,\n",
    "                    \"Model\": model_name,\n",
    "                    \"Method\": method,\n",
    "                    \"Test_RMSE\": avg_rmse,\n",
    "                })\n",
    "\n",
    "    # Long -> wide\n",
    "    df_long = pd.DataFrame(rows)\n",
    "\n",
    "    return df_long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------\n",
    "# # Driver\n",
    "# # -----------------------------\n",
    "\n",
    "# # Phase 1: train and save predictions\n",
    "# generate_and_save_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Phase 2: reload and compute RMSE table\n",
    "df_long = compute_rmse_from_saved_predictions()\n",
    "\n",
    "# Save outputs for convenience\n",
    "\n",
    "# Also pickle the DataFrame if you want to load it later\n",
    "with open(os.path.join(PREDICTIONS_DIR, \"rmse_averaged.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(df_long, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '_fold_data' from Dataset column\n",
    "df_long['Dataset'] = df_long['Dataset'].str.replace('_fold_data', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Best K Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Dataset                                  Model Method  \\\n",
      "0     Airfoil_Self_Noise                      Linear Regression  BASIC   \n",
      "1     Airfoil_Self_Noise                         KNN Regression  BASIC   \n",
      "2     Airfoil_Self_Noise                         SVM Regression  BASIC   \n",
      "3     Airfoil_Self_Noise               Random Forest Regression  BASIC   \n",
      "4     Airfoil_Self_Noise                    AdaBoost Regression  BASIC   \n",
      "...                  ...                                    ...    ...   \n",
      "1293               Quake               Decision Tree Regression    EFS   \n",
      "1294               Quake  Extremely Randomized Trees Regression    EFS   \n",
      "1295               Quake           Gradient Boosting Regression    EFS   \n",
      "1296               Quake                    LightGBM Regression    EFS   \n",
      "1297               Quake                     XGBoost Regression    EFS   \n",
      "\n",
      "      Test_RMSE  \n",
      "0      4.850325  \n",
      "1      3.578602  \n",
      "2      4.235507  \n",
      "3      1.826100  \n",
      "4      3.878246  \n",
      "...         ...  \n",
      "1293   0.246607  \n",
      "1294   0.207109  \n",
      "1295   0.191389  \n",
      "1296   0.192823  \n",
      "1297   0.199665  \n",
      "\n",
      "[1298 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickled df_summary\n",
    "with open('df_summary.pkl', 'rb') as f:\n",
    "    df_summary_loaded = pickle.load(f)\n",
    "\n",
    "# Append df_summary to df_long\n",
    "df_long = pd.concat([df_long, df_summary_loaded], ignore_index=True)\n",
    "\n",
    "print(df_long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method             Dataset                                  Model     BASIC  \\\n",
      "0       Airfoil_Self_Noise                    AdaBoost Regression  3.878246   \n",
      "1       Airfoil_Self_Noise               Decision Tree Regression  2.658327   \n",
      "2       Airfoil_Self_Noise  Extremely Randomized Trees Regression  1.548887   \n",
      "3       Airfoil_Self_Noise           Gradient Boosting Regression  2.684646   \n",
      "4       Airfoil_Self_Noise                         KNN Regression  3.578602   \n",
      "..                     ...                                    ...       ...   \n",
      "226                  pyrim                      Linear Regression  0.166263   \n",
      "227                  pyrim                         MLP Regression  0.162682   \n",
      "228                  pyrim               Random Forest Regression  0.089179   \n",
      "229                  pyrim                         SVM Regression  0.096645   \n",
      "230                  pyrim                     XGBoost Regression  0.088489   \n",
      "\n",
      "Method  AUTOFEAT        FT      SAFE       EFS    OPENFE  \n",
      "0       3.112117  3.358413  6.241048  3.900947       NaN  \n",
      "1       2.674541  3.579752  3.827838  2.600152       NaN  \n",
      "2       1.542916  2.345341  3.765959  1.537636       NaN  \n",
      "3       2.043500  2.506068  4.784497  2.674041       NaN  \n",
      "4       2.651513  4.583180  5.135852  3.645315       NaN  \n",
      "..           ...       ...       ...       ...       ...  \n",
      "226          NaN  0.091886  0.118666  0.108104  0.166263  \n",
      "227          NaN  0.158718  0.122773  0.112684  0.116194  \n",
      "228          NaN  0.091970  0.118772  0.093879  0.087186  \n",
      "229          NaN  0.104059  0.116097  0.099734  0.096513  \n",
      "230          NaN  0.086648  0.118664  0.098936  0.088489  \n",
      "\n",
      "[231 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pivot the dataframe\n",
    "df_wide = df_long.pivot_table(\n",
    "    index=['Dataset', 'Model'],   # Keep these as identifiers\n",
    "    columns='Method',             # Each method becomes a column\n",
    "    values='Test_RMSE'            # Fill with Test_RMSE values\n",
    ").reset_index()\n",
    "\n",
    "# Optional: ensure the column order you mentioned\n",
    "method_order = ['BASIC', 'AUTOFEAT', 'FT', 'SAFE', 'EFS', 'OPENFE']\n",
    "df_wide = df_wide[['Dataset', 'Model'] + method_order]\n",
    "\n",
    "print(df_wide)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Fertility as it is a classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where Dataset contains 'Fertility'\n",
    "df_wide = df_wide[~df_wide['Dataset'].str.contains('Fertility', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "methods_to_compare = ['BASIC', 'AUTOFEAT', 'FT', 'SAFE', 'OPENFE']\n",
    "\n",
    "def classify_outcome(row, compare_method):\n",
    "    if row['EFS'] < row[compare_method]:\n",
    "        return \"Improved\"\n",
    "    elif row['EFS'] == row[compare_method]:\n",
    "        return \"Same\"\n",
    "    else:\n",
    "        return \"Decreased\"\n",
    "\n",
    "for method in methods_to_compare:\n",
    "    # Drop rows where either EFS or the method is NaN\n",
    "    temp_df = df_wide.dropna(subset=['EFS', method]).copy()\n",
    "    temp_df['Outcome'] = temp_df.apply(lambda row: classify_outcome(row, method), axis=1)\n",
    "\n",
    "    counts = (\n",
    "        temp_df.groupby(['Model', 'Outcome'])\n",
    "               .size()\n",
    "               .reset_index(name='Count')\n",
    "    )\n",
    "\n",
    "    total_per_model = counts.groupby('Model')['Count'].transform('sum')\n",
    "    counts['Percentage'] = (counts['Count'] / total_per_model) * 100\n",
    "\n",
    "    # Pivot and ensure all outcome columns exist\n",
    "    plot_df = counts.pivot(index='Model', columns='Outcome', values='Percentage').fillna(0)\n",
    "    for col in [\"Improved\", \"Same\", \"Decreased\"]:\n",
    "        if col not in plot_df.columns:\n",
    "            plot_df[col] = 0\n",
    "    plot_df = plot_df[[\"Improved\", \"Same\", \"Decreased\"]]  # enforce column order\n",
    "\n",
    "    # Plot\n",
    "    plot_df.plot(kind='bar', stacked=False)\n",
    "    plt.ylabel(\"Percentage (%)\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels vertically\n",
    "    plt.legend(title=\"Outcome\", loc=\"upper left\", bbox_to_anchor=(1.05, 1))\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save as PDF (lowercase method name in filename, spaces replaced with underscores)\n",
    "    filename = f\"{method.lower()}_comparison.pdf\".replace(\" \", \"_\")\n",
    "    plt.savefig(filename, format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.close()  # Close the figure to free memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing AFE against Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "methods_to_compare = ['AUTOFEAT', 'FT', 'SAFE', 'OPENFE']\n",
    "\n",
    "def classify_outcome(row, compare_method):\n",
    "    if row['BASIC'] > row[compare_method]:\n",
    "        return \"Improved\"\n",
    "    elif row['BASIC'] == row[compare_method]:\n",
    "        return \"Same\"\n",
    "    else:\n",
    "        return \"Decreased\"\n",
    "\n",
    "for method in methods_to_compare:\n",
    "    # Drop rows where either EFS or the method is NaN\n",
    "    temp_df = df_wide.dropna(subset=['EFS', method]).copy()\n",
    "    temp_df['Outcome'] = temp_df.apply(lambda row: classify_outcome(row, method), axis=1)\n",
    "\n",
    "    counts = (\n",
    "        temp_df.groupby(['Model', 'Outcome'])\n",
    "               .size()\n",
    "               .reset_index(name='Count')\n",
    "    )\n",
    "\n",
    "    total_per_model = counts.groupby('Model')['Count'].transform('sum')\n",
    "    counts['Percentage'] = (counts['Count'] / total_per_model) * 100\n",
    "\n",
    "    # Pivot and ensure all outcome columns exist\n",
    "    plot_df = counts.pivot(index='Model', columns='Outcome', values='Percentage').fillna(0)\n",
    "    for col in [\"Improved\", \"Same\", \"Decreased\"]:\n",
    "        if col not in plot_df.columns:\n",
    "            plot_df[col] = 0\n",
    "    plot_df = plot_df[[\"Improved\", \"Same\", \"Decreased\"]]  # enforce column order\n",
    "\n",
    "    # Plot\n",
    "    plot_df.plot(kind='bar', stacked=False)\n",
    "    plt.ylabel(\"Percentage (%)\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels vertically\n",
    "    plt.legend(title=\"Outcome\", loc=\"upper left\", bbox_to_anchor=(1.05, 1))\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save as PDF (lowercase method name in filename, spaces replaced with underscores)\n",
    "    filename = f\"{method.lower()}_basic_comparison.pdf\".replace(\" \", \"_\")\n",
    "    plt.savefig(filename, format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.close()  # Close the figure to free memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for significant differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Wilcoxon_stat   p_value  \\\n",
      "0                     AdaBoost Regression           98.0  0.406178   \n",
      "1                Decision Tree Regression          112.0  0.753049   \n",
      "2   Extremely Randomized Trees Regression          102.0  0.610911   \n",
      "3            Gradient Boosting Regression           95.0  0.809418   \n",
      "4                          KNN Regression          168.0  0.992344   \n",
      "5                     LightGBM Regression           79.0  0.388559   \n",
      "6                       Linear Regression           71.0  0.561639   \n",
      "7                          MLP Regression          142.0  0.993065   \n",
      "8                Random Forest Regression           99.0  0.563941   \n",
      "9                          SVM Regression          133.0  0.999612   \n",
      "10                     XGBoost Regression           78.0  0.371975   \n",
      "\n",
      "    Significant_(p<0.05)  \n",
      "0                  False  \n",
      "1                  False  \n",
      "2                  False  \n",
      "3                  False  \n",
      "4                  False  \n",
      "5                  False  \n",
      "6                  False  \n",
      "7                  False  \n",
      "8                  False  \n",
      "9                  False  \n",
      "10                 False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def compare_basic_lt_efs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run Wilcoxon signed-rank test per model to check if BASIC < EFS.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model in df['Model'].unique():\n",
    "        subset = df[df['Model'] == model]\n",
    "\n",
    "        # Paired values\n",
    "        basic_vals = subset['BASIC'].values\n",
    "        efs_vals = subset['EFS'].values\n",
    "\n",
    "        # One-sided test: BASIC < EFS\n",
    "        stat, p_value = wilcoxon(basic_vals, efs_vals, alternative='less')\n",
    "\n",
    "        results.append({\n",
    "            'Model': model,\n",
    "            'Wilcoxon_stat': stat,\n",
    "            'p_value': p_value,\n",
    "            'Significant_(p<0.05)': p_value < 0.05\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage\n",
    "df_results = compare_basic_lt_efs(df_wide)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking globally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Comparison  Wilcoxon_stat   p_value  Significant\n",
      "0  EFS vs BASIC         7046.0  0.000123         True\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Paired samples\n",
    "basic_vals = df_wide['BASIC'].values\n",
    "efs_vals = df_wide['EFS'].values\n",
    "\n",
    "# One-sided Wilcoxon: test if EFS < BASIC\n",
    "stat, p_value = wilcoxon(efs_vals, basic_vals, alternative='less')\n",
    "\n",
    "# Put results in a dataframe\n",
    "df_results = pd.DataFrame([{\n",
    "    'Comparison': 'EFS vs BASIC',\n",
    "    'Wilcoxon_stat': stat,\n",
    "    'p_value': p_value,\n",
    "    'Significant': p_value < 0.05\n",
    "}])\n",
    "\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for AFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BASIC < AUTOFEAT (per model) ===\n",
      "                                    Model    Method  n_pairs  n_zero_diffs  \\\n",
      "0                     AdaBoost Regression  AUTOFEAT       19             0   \n",
      "1                Decision Tree Regression  AUTOFEAT       19             0   \n",
      "2   Extremely Randomized Trees Regression  AUTOFEAT       19             0   \n",
      "3            Gradient Boosting Regression  AUTOFEAT       19             0   \n",
      "4                          KNN Regression  AUTOFEAT       19             0   \n",
      "5                     LightGBM Regression  AUTOFEAT       19             0   \n",
      "6                       Linear Regression  AUTOFEAT       19             0   \n",
      "7                          MLP Regression  AUTOFEAT       19             0   \n",
      "8                Random Forest Regression  AUTOFEAT       19             0   \n",
      "9                          SVM Regression  AUTOFEAT       19             0   \n",
      "10                     XGBoost Regression  AUTOFEAT       19             0   \n",
      "\n",
      "    Wilcoxon_stat   p_value  Significant_(p<0.05)  \n",
      "0           124.0  0.879374                 False  \n",
      "1            89.0  0.414392                 False  \n",
      "2           100.0  0.585608                 False  \n",
      "3           123.0  0.871037                 False  \n",
      "4           170.0  0.999414                 False  \n",
      "5           138.0  0.960062                 False  \n",
      "6           112.0  0.755016                 False  \n",
      "7           168.0  0.999153                 False  \n",
      "8            82.0  0.311281                 False  \n",
      "9           166.0  0.998800                 False  \n",
      "10           74.0  0.209021                 False  \n",
      "\n",
      "=== BASIC < FT (per model) ===\n",
      "                                    Model Method  n_pairs  n_zero_diffs  \\\n",
      "0                     AdaBoost Regression     FT       20             0   \n",
      "1                Decision Tree Regression     FT       20             0   \n",
      "2   Extremely Randomized Trees Regression     FT       20             0   \n",
      "3            Gradient Boosting Regression     FT       20             0   \n",
      "4                          KNN Regression     FT       20             0   \n",
      "5                     LightGBM Regression     FT       20             0   \n",
      "6                       Linear Regression     FT       20             0   \n",
      "7                          MLP Regression     FT       20             0   \n",
      "8                Random Forest Regression     FT       20             0   \n",
      "9                          SVM Regression     FT       20             0   \n",
      "10                     XGBoost Regression     FT       20             0   \n",
      "\n",
      "    Wilcoxon_stat       p_value  Significant_(p<0.05)  \n",
      "0           129.0  8.158617e-01                 False  \n",
      "1             0.0  9.536743e-07                  True  \n",
      "2            30.0  1.827240e-03                  True  \n",
      "3            90.0  2.979097e-01                 False  \n",
      "4            99.0  4.204111e-01                 False  \n",
      "5            12.0  6.675720e-05                  True  \n",
      "6            25.0  8.449554e-04                  True  \n",
      "7           119.0  7.020903e-01                 False  \n",
      "8            17.0  1.974106e-04                  True  \n",
      "9            65.0  7.145309e-02                 False  \n",
      "10            8.0  2.384186e-05                  True  \n",
      "\n",
      "=== BASIC < SAFE (per model) ===\n",
      "                                    Model Method  n_pairs  n_zero_diffs  \\\n",
      "0                     AdaBoost Regression   SAFE       20             0   \n",
      "1                Decision Tree Regression   SAFE       20             0   \n",
      "2   Extremely Randomized Trees Regression   SAFE       20             0   \n",
      "3            Gradient Boosting Regression   SAFE       20             0   \n",
      "4                          KNN Regression   SAFE       20             0   \n",
      "5                     LightGBM Regression   SAFE       20             0   \n",
      "6                       Linear Regression   SAFE       20             0   \n",
      "7                          MLP Regression   SAFE       20             0   \n",
      "8                Random Forest Regression   SAFE       20             0   \n",
      "9                          SVM Regression   SAFE       20             0   \n",
      "10                     XGBoost Regression   SAFE       20             0   \n",
      "\n",
      "    Wilcoxon_stat   p_value  Significant_(p<0.05)  \n",
      "0             1.0  0.000002                  True  \n",
      "1            54.0  0.029129                  True  \n",
      "2             1.0  0.000002                  True  \n",
      "3            34.0  0.003195                  True  \n",
      "4            77.0  0.155897                 False  \n",
      "5            17.0  0.000197                  True  \n",
      "6           139.0  0.898775                 False  \n",
      "7           188.0  0.999575                 False  \n",
      "8            20.0  0.000354                  True  \n",
      "9            78.0  0.164991                 False  \n",
      "10           33.0  0.002790                  True  \n",
      "\n",
      "=== BASIC < OPENFE (per model) ===\n",
      "                                    Model  Method  n_pairs  n_zero_diffs  \\\n",
      "0                     AdaBoost Regression  OPENFE       18             0   \n",
      "1                Decision Tree Regression  OPENFE       18             0   \n",
      "2   Extremely Randomized Trees Regression  OPENFE       18             0   \n",
      "3            Gradient Boosting Regression  OPENFE       18             0   \n",
      "4                          KNN Regression  OPENFE       18             2   \n",
      "5                     LightGBM Regression  OPENFE       18             2   \n",
      "6                       Linear Regression  OPENFE       18             2   \n",
      "7                          MLP Regression  OPENFE       18             0   \n",
      "8                Random Forest Regression  OPENFE       18             0   \n",
      "9                          SVM Regression  OPENFE       18             0   \n",
      "10                     XGBoost Regression  OPENFE       18             2   \n",
      "\n",
      "    Wilcoxon_stat   p_value  Significant_(p<0.05)  \n",
      "0           143.0  0.995518                 False  \n",
      "1            98.0  0.710079                 False  \n",
      "2           143.0  0.995518                 False  \n",
      "3           136.0  0.988163                 False  \n",
      "4           102.0  0.960635                 False  \n",
      "5           116.0  0.993468                 False  \n",
      "6            33.0  0.035163                  True  \n",
      "7           155.0  0.999477                 False  \n",
      "8           114.0  0.893929                 False  \n",
      "9           121.0  0.940647                 False  \n",
      "10           61.0  0.358690                 False  \n",
      "\n",
      "=== BASIC < EFS (per model) ===\n",
      "                                    Model Method  n_pairs  n_zero_diffs  \\\n",
      "0                     AdaBoost Regression    EFS       20             0   \n",
      "1                Decision Tree Regression    EFS       20             1   \n",
      "2   Extremely Randomized Trees Regression    EFS       20             1   \n",
      "3            Gradient Boosting Regression    EFS       20             3   \n",
      "4                          KNN Regression    EFS       20             0   \n",
      "5                     LightGBM Regression    EFS       20             2   \n",
      "6                       Linear Regression    EFS       20             4   \n",
      "7                          MLP Regression    EFS       20             2   \n",
      "8                Random Forest Regression    EFS       20             1   \n",
      "9                          SVM Regression    EFS       20             4   \n",
      "10                     XGBoost Regression    EFS       20             2   \n",
      "\n",
      "    Wilcoxon_stat   p_value  Significant_(p<0.05)  \n",
      "0            98.0  0.406178                 False  \n",
      "1           112.0  0.753049                 False  \n",
      "2           102.0  0.610911                 False  \n",
      "3            95.0  0.809418                 False  \n",
      "4           168.0  0.992344                 False  \n",
      "5            79.0  0.388559                 False  \n",
      "6            71.0  0.561639                 False  \n",
      "7           142.0  0.993065                 False  \n",
      "8            99.0  0.563941                 False  \n",
      "9           133.0  0.999612                 False  \n",
      "10           78.0  0.371975                 False  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "def wilcoxon_basic_lt_method_by_model(df: pd.DataFrame, method_col: str, alpha: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each Model, run a one-sided Wilcoxon signed-rank test to check if BASIC < AFE method.\n",
    "    - Pairs are (BASIC, method_col) across datasets within each Model.\n",
    "    - NaN rows are dropped per-model.\n",
    "    - If all paired differences are zero or there are fewer than 1 valid pairs, returns NaNs for stat/p.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for model, sub in df.groupby('Model', dropna=False):\n",
    "        # Keep only rows where both columns are present\n",
    "        paired = sub[['BASIC', method_col]].dropna()\n",
    "\n",
    "        # Count pairs\n",
    "        n_pairs = len(paired)\n",
    "        stat = np.nan\n",
    "        pval = np.nan\n",
    "        significant = False\n",
    "        n_zero = 0\n",
    "\n",
    "        if n_pairs > 0:\n",
    "            x = paired['BASIC'].to_numpy()\n",
    "            y = paired[method_col].to_numpy()\n",
    "            diffs = x - y\n",
    "            n_zero = int(np.sum(diffs == 0))\n",
    "\n",
    "            # Need at least one non-zero difference for Wilcoxon to run\n",
    "            if np.any(diffs != 0):\n",
    "                stat, pval = wilcoxon(x, y, alternative='less', zero_method='wilcox')\n",
    "                significant = bool(pval < alpha)\n",
    "\n",
    "        rows.append({\n",
    "            'Model': model,\n",
    "            'Method': method_col,\n",
    "            'n_pairs': n_pairs,\n",
    "            'n_zero_diffs': n_zero,\n",
    "            'Wilcoxon_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'Significant_(p<{})'.format(alpha): significant\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values('Model').reset_index(drop=True)\n",
    "\n",
    "# ---- Run for each AFE method (BASIC < METHOD) ----\n",
    "df_res_AUTOF   = wilcoxon_basic_lt_method_by_model(df_wide, 'AUTOFEAT')\n",
    "df_res_FT      = wilcoxon_basic_lt_method_by_model(df_wide, 'FT')\n",
    "df_res_SAFE    = wilcoxon_basic_lt_method_by_model(df_wide, 'SAFE')\n",
    "df_res_OPENFE  = wilcoxon_basic_lt_method_by_model(df_wide, 'OPENFE')\n",
    "df_EFS         = wilcoxon_basic_lt_method_by_model(df_wide, 'EFS')\n",
    "\n",
    "\n",
    "# Optional: display / inspect\n",
    "for name, d in [('AUTOFEAT', df_res_AUTOF),\n",
    "                ('FT', df_res_FT),\n",
    "                ('SAFE', df_res_SAFE),\n",
    "                ('OPENFE', df_res_OPENFE),\n",
    "                ('EFS', df_EFS)]:\n",
    "    print(f\"\\n=== BASIC < {name} (per model) ===\")\n",
    "    print(d)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
